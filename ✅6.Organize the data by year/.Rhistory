}
}
}
}
}
} else {
cat("\n", crayon::red("Data copy cancelled."), "\n")
}
}
}
# ğŸŸ§ ëª¨ë“  ì—°ë„ í•©ì¹˜ëŠ” í•¨ìˆ˜ (ìµœë¹ˆê°’ ê¸°ì¤€) ================================================================
process_and_export_most_frequent_value_rows <- function(path_to, output_file) {
# ì§€ì •ëœ ê²½ë¡œì—ì„œ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
files <- list.files(path_to, full.names = TRUE)
# "ì—°ë„.csv" í˜•íƒœì˜ íŒŒì¼ë§Œ í•„í„°ë§
csv_files <- files[grepl("_[0-9]{4}\\.csv$", files)]
# íŒŒì¼ì„ ì—°ë„ ìˆœì„œëŒ€ë¡œ ì •ë ¬
csv_files <- csv_files[order(as.numeric(gsub(".*_([0-9]{4})\\.csv$", "\\1", csv_files)))]
# íŒŒì¼ì´ í•˜ë‚˜ë§Œ ì¡´ì¬í•˜ëŠ” ê²½ìš° í•¨ìˆ˜ ì‹¤í–‰ ìƒëµ
if (length(csv_files) <= 1) {
cat("\n", crayon::red("íŒŒì¼ì´ í•˜ë‚˜ë§Œ ì¡´ì¬í•˜ê±°ë‚˜ ì—†ìŠµë‹ˆë‹¤. í•¨ìˆ˜ ì‹¤í–‰ì„ ìƒëµí•©ë‹ˆë‹¤."), "\n")
return(NULL)
}
# ê° íŒŒì¼ì„ ì½ê³  Value_newì˜ ìµœë¹ˆê°’ í–‰ë§Œ ì¶”ì¶œ
most_frequent_value_rows <- lapply(csv_files, function(file) {
df <- read_csv(file, show_col_types = FALSE)
# ìµœë¹ˆê°’ ê³„ì‚°
most_frequent_value <- as.numeric(names(sort(table(df$Value_new), decreasing = TRUE)[1]))
most_frequent_rows <- df %>% filter(Value_new == most_frequent_value)
# Classification ì—´ì„ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ì˜¤ë˜ëœ ì—°ë„ ì„ íƒ
selected_row <- most_frequent_rows %>% arrange(Sub_Sub_Category) %>% slice(1)
# Sub_Sub_Category ì—´ì„ characterë¡œ ë³€í™˜
selected_row <- selected_row %>% mutate(Sub_Sub_Category = as.character(Sub_Sub_Category))
return(selected_row)
})
# ëª¨ë“  ì¶”ì¶œí•œ í–‰ë“¤ì„ í•˜ë‚˜ì˜ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í•©ì¹˜ê¸°
combined_df <- bind_rows(most_frequent_value_rows)
# Sub_Sub_Categoryì™€ Value_newê°€ ì œëŒ€ë¡œ ì½íˆë„ë¡ í˜• ë³€í™˜
combined_df <- combined_df %>%
mutate(Sub_Sub_Category = as.factor(Sub_Sub_Category), Value_new = as.numeric(Value_new))
# View(combined_df)
# ì—°ë„ ìˆœì„œ í™•ì¸
years = combined_df$Sub_Sub_Category %>% gsub("ê¹Œì§€", "", .) %>% as.numeric %>% sort
all_years_present <- all(diff(years) == 1)
first_year <- min(years)
last_year <- max(years)
if (all_years_present) {
output_file <- paste0(output_file, "_complete")
message <- sprintf("ëª¨ë“  ì—°ë„ê°€ 1ë…„ ì°¨ì´ë¡œ ì¡´ì¬í•©ë‹ˆë‹¤. (%dë…„ë¶€í„° %dë…„ê¹Œì§€)", first_year, last_year)
} else {
output_file <- paste0(output_file, "_incomplete")
message <- sprintf("ì—°ë„ ì‚¬ì´ì— ëˆ„ë½ëœ ì—°ë„ê°€ ìˆìŠµë‹ˆë‹¤. (%dë…„ë¶€í„° %dë…„ê¹Œì§€)", first_year, last_year)
}
# ì§€ì •í•œ íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ ë‚´ë³´ë‚´ê¸°
write_csv(combined_df, file.path(path_to, paste0(output_file, ".csv")))
# ggplotì„ ì´ìš©í•œ timeseries plot ìƒì„±
p <- ggplot(combined_df, aes(x = Sub_Sub_Category, y = Value_new, group = 1)) +
geom_line(color = "blue") +
geom_point(color = "red") +
theme_minimal() +
theme(
plot.background = element_rect(fill = "white", color = "white"),
panel.background = element_rect(fill = "white", color = "white"),
axis.text.x = element_text(angle = 45, hjust = 1)
) +
labs(title = "Time Series of Value_new",
x = "Sub_Sub_Category",
y = "Value_new") +
scale_x_discrete(expand = c(0, 0))
# plotì„ PNG í˜•ì‹ìœ¼ë¡œ ì €ì¥
ggsave(filename = file.path(path_to, paste0(output_file, ".png")), plot = p, bg = "white", width = 10, height = 6)
# ë©”ì‹œì§€ ì¶œë ¥
cat("\n", crayon::magenta(message), "\n")
}
## ğŸŸ§ ê²½ë¡œì˜ ì¶”ì¶œí•  í•­ëª©ë“¤ í™•ì¸ ====================================================================================================
# í•¨ìˆ˜ ì •ì˜
extract_unique_categories <- function(path) {
# ì§€ì •ëœ ê²½ë¡œì—ì„œ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (ì¬ê·€ì ìœ¼ë¡œ í•˜ìœ„ í´ë” í¬í•¨)
files <- list.files(path, full.names = TRUE, recursive = TRUE)
# íŒŒì¼ ì´ë¦„ë§Œ ì¶”ì¶œ
file_names <- basename(files)
# "ì—°ë„_"ì™€ ì²« ë²ˆì§¸ "___" ì‚¬ì´ì˜ ë¬¸ìì—´ ì¶”ì¶œ
categories <- str_extract(file_names, "(?<=^[0-9]{4}_)[^_]+")
# ì¤‘ë³µ ì œê±° í›„ ë°˜í™˜
unique_categories <- unique(categories)
return(unique_categories)
}
## ğŸŸ§ csv íŒŒì¼ë“¤ ì²˜ë¦¬ ====================================================================================================
library(dplyr)
process_csv_files <- function(path, colnames, which_year) {
# íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
files <- list.files(path, pattern = "\\.csv$", full.names = TRUE)
# ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
results <- list()
for (file in files) {
# CSV íŒŒì¼ ì½ê¸°
data <- read.csv(file)
# ì—´ ì´ë¦„ í™•ì¸
col_names <- colnames(data)
# 3ë²ˆì§¸ ì—´ì˜ ê°’ ì¶”ì¶œ
third_column <- data[[3]]
# ì—°ë„ë§Œ ì¶”ì¶œ (ì •ê·œí‘œí˜„ì‹ ì‚¬ìš©)
years <- third_column[grep("\\d{4}", third_column)]
# which_yearì— í•´ë‹¹í•˜ëŠ” í–‰ ì¶”ì¶œ
rows_with_year <- data[grep(which_year, third_column), ]
# colnames ë‚´ ëª¨ë“  ë¬¸ìì—´ì„ í¬í•¨í•˜ëŠ” ì—´ ì°¾ê¸° (4ë²ˆì§¸ ì—´ë¶€í„° Categorized_L3_New ì´ì „ê¹Œì§€)
start_col <- 4
end_col <- which(col_names == "Categorized_L3_New") - 1
if (length(end_col) == 0) {
stop("Categorized_L3_New ì—´ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
}
# colnames ë‚´ ëª¨ë“  ë¬¸ìì—´ì„ í¬í•¨í•˜ëŠ” ì—´ ì°¾ê¸°
matching_cols <- col_names[start_col:end_col]
target_cols <- matching_cols[sapply(matching_cols, function(x) all(sapply(colnames, function(y) grepl(y, x))))]
if (length(target_cols) == 0) {
warning(paste("íŒŒì¼", file, "ì—ì„œ ëª¨ë“  colnamesì— í•´ë‹¹í•˜ëŠ” ì—´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."))
next
}
# ê²°ê³¼ ì €ì¥
results[[file]] <- list(
rows_with_year = rows_with_year,
target_cols = target_cols
)
}
return(results)
}
## ğŸŸ§ ì—°ë„ í•©ê³„ íŒŒì¼ì´ ì•„ë‹Œ íŒŒì¼ë“¤ ì‚­ì œ ====================================================================================================
delete_non_year_files <- function(directory) {
# ëª¨ë“  csv íŒŒì¼ì„ ì¬ê·€ì ìœ¼ë¡œ ì°¾ê¸°
files <- list.files(directory, pattern = "\\.csv$", recursive = TRUE, full.names = TRUE)
# ì—°ë„ ë˜ëŠ” ì—°ë„ë¥¼ í¬í•¨í•œ ë¬¸ìì—´ì„ íŒë‹¨í•˜ê¸° ìœ„í•œ ì •ê·œ í‘œí˜„ì‹
year_regex <- "^[0-9]{4}.*$"
# íŒŒì¼ ì‚­ì œ ì¹´ìš´í„°
deleted_files <- 0
for (file in files) {
# íŒŒì¼ ì´ë¦„ì—ì„œ í™•ì¥ì ì œê±°
file_name <- basename(file)
file_name <- sub("\\.csv$", "", file_name)
# íŒŒì¼ ì´ë¦„ì„ "___"ë¡œ ë¶„í• 
parts <- unlist(strsplit(file_name, "___"))
# ë‘ ë²ˆì§¸ ë¶€ë¶„ì´ ì—°ë„ ë˜ëŠ” ì—°ë„ë¥¼ í¬í•¨í•œ ë¬¸ìì—´ì¸ì§€ í™•ì¸
if (length(parts) >= 2) {
second_part <- parts[2]
if (!grepl(year_regex, second_part)) {
# ì—°ë„ ë˜ëŠ” ì—°ë„ë¥¼ í¬í•¨í•œ ë¬¸ìì—´ì´ ì•„ë‹ˆë©´ íŒŒì¼ ì‚­ì œ
file.remove(file)
deleted_files <- deleted_files + 1
cat("Deleted:", file, "\n")
}
}
}
cat("Total files deleted:", deleted_files, "\n")
}
## ğŸŸ§ ì—°ë„ë³„ ë‚´ë³´ë‚´ê³  ìµœë¹ˆê°’ìœ¼ë¡œ í•©ì¹˜ê¸° ====================================================================================================
each_year_total_copy_data_by_year_by_max_value_rows = function(yb,
path_from,
path_to,
L3,
item,
years_regions = c(),
total_include.list,
total_exclude.list,
message = T,
remove.files = F){
# path_to = path_to_upper
if(length(years_regions) > 0){
for(k in seq_along(total_include.list)){
# k=1
# k=i=1
# i=26
tryCatch({
cat(crayon::blue("\nStarting outer loop with k = "), k, "\n")
for(i in seq_along(years_regions)){
cat(crayon::blue(k, i, "\n"))
tryCatch({
cat(crayon::blue("  Starting inner loop with k = "), k, " and i = ", i, "\n")
ith_year = years_regions[i]
# change
kth_include.list = lapply(total_include.list[[k]], function(x){ c(x, ith_year) })
kth_exclude.list = total_exclude.list[[k]]
kth_sub_category = names(total_include.list)[k]
kth_path_to = file.path(path_to, kth_sub_category) # path ì„¤ì •
# function
ith_results = copy_data_by_year(yb,
path_from,
path_to = kth_path_to,
save_file_name = paste0(L3, "___", kth_sub_category, "___", ith_year),
include.list = kth_include.list,
exclude.list = kth_exclude.list,
message,
remove.files)
cat(crayon::blue("  Finished inner loop with k = "), k, " and i = ", i, "\n")
}, error = function(e) {
cat(crayon::red("Error in inner loop with k = "), k, " and i = ", i, ": ", e$message, "\n")
stop(e)
})
}
# remove.files=F
tryCatch({
# ê° ì¶”ì¶œëœ ì—°ë„ë³„ ë°ì´í„° í•©ì¹˜ê¸° (ìµœë¹ˆê°’ ê¸°ì¤€)
process_and_export_most_frequent_value_rows(path_to = kth_path_to, output_file = paste0(L3, "___", kth_sub_category, "___Total"))
cat(crayon::green("Exporting is done: "), crayon::bgMagenta(paste0(L3, "_", kth_sub_category)), "\n")
}, error = function(e) {
cat(crayon::red("Error in process_and_export_most_frequent_value_rows with k = "), k, ": ", e$message, "\n")
stop(e)
})
cat(crayon::blue("Finished outer loop with k = "), k, "\n")
}, error = function(e) {
cat(crayon::red("Error in outer loop with k = "), k, " and last i = ", if (exists("i")) i else "not started", ": ", e$message, "\n")
stop(e)
})
}
}else{
for(k in seq_along(total_include.list)){
# k=1
# k=i=1
# i=26
tryCatch({
cat(crayon::blue("\nStarting outer loop with k = "), k, "\n")
tryCatch({
# change
kth_include.list = total_include.list[[k]]
kth_exclude.list = total_exclude.list[[k]]
kth_sub_category = names(total_include.list)[k]
# kth_path_to = file.path(path_to, kth_sub_category) # path ì„¤ì •
# function
kth_results = copy_data_by_year(yb,
path_from,
path_to = path_to,
save_file_name = paste0(kth_sub_category),
include.list = kth_include.list,
exclude.list = kth_exclude.list,
message,
remove.files)
}, error = function(e) {
cat(crayon::red("Error in inner loop with k = "), k, " and i = ", i, ": ", e$message, "\n")
stop(e)
})
# remove.files=F
# tryCatch({
#   # ê° ì¶”ì¶œëœ ì—°ë„ë³„ ë°ì´í„° í•©ì¹˜ê¸° (ìµœë¹ˆê°’ ê¸°ì¤€)
#   process_and_export_most_frequent_value_rows(path_to = kth_path_to, output_file = paste0(L3, "___", kth_sub_category, "___Total"))
#
#   cat(crayon::green("Exporting is done: "), crayon::bgMagenta(paste0(L3, "_", kth_sub_category)), "\n")
# }, error = function(e) {
#   cat(crayon::red("Error in process_and_export_most_frequent_value_rows with k = "), k, ": ", e$message, "\n")
#   stop(e)
# })
cat(crayon::blue("Finished outer loop with k = "), k, "\n")
}, error = function(e) {
cat(crayon::red("Error in outer loop with k = "), k, " and last i = ", if (exists("i")) i else "not started", ": ", e$message, "\n")
stop(e)
})
}
}
}
# message=F
## ğŸŸ§ ë¦¬ìŠ¤íŠ¸ 2ê°œ ë¹„êµ =============================================================
# ë‘ ê°œì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¹„êµí•˜ì—¬ ê¸¸ì´ì™€ ì›ì†Œ ì´ë¦„ì´ ë™ì¼í•œì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
# ë‘ ê°œì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¹„êµí•˜ì—¬ ê¸¸ì´ì™€ ì›ì†Œ ì´ë¦„ì´ ë™ì¼í•œì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
library(crayon)
# ë‘ ê°œì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¹„êµí•˜ì—¬ ê¸¸ì´ì™€ ì›ì†Œ ì´ë¦„ì´ ë™ì¼í•œì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
compare_lists <- function(list1, list2) {
# ë‘ ë¦¬ìŠ¤íŠ¸ì˜ ê¸¸ì´ ë¹„êµ
if (length(list1) != length(list2)) {
cat(red("The lists have different lengths.\n"))
return(FALSE)
}
# ë‘ ë¦¬ìŠ¤íŠ¸ì˜ ì›ì†Œ ì´ë¦„ ë¹„êµ
names1 <- names(list1)
names2 <- names(list2)
if (is.null(names1) || is.null(names2)) {
cat(red("One or both of the lists do not have names.\n"))
return(FALSE)
}
if (!all(names1 == names2)) {
cat(red("The lists have different names.\n"))
return(FALSE)
}
cat(green("The lists have the same length and names.\n"))
return(TRUE)
}
## ğŸŸ§ csv íŒŒì¼ í•„ ========================================================================
get_filtered_csv_files <- function(path, include = NULL, exclude = NULL) {
# Load necessary library
library(stringr)
# List all CSV files recursively
all_files <- list.files(path, pattern = "\\.csv$", recursive = TRUE, full.names = FALSE)
# Extract the specific part of the file name
extract_name_part <- function(filename) {
parts <- str_split(filename, "___")[[1]]
if (length(parts) >= 2) {
return(paste(parts[1], parts[2], sep = "___"))
} else {
return(NA)
}
}
extracted_names <- sapply(all_files, extract_name_part)
valid_files <- !is.na(extracted_names)
extracted_names <- extracted_names[valid_files]
all_files <- all_files[valid_files]
# Filter based on include criteria (all strings in include must be present)
if (!is.null(include)) {
include_indices <- sapply(include, function(inc) grepl(inc, extracted_names))
include_indices <- apply(include_indices, 1, all)
} else {
include_indices <- rep(TRUE, length(extracted_names))
}
# Filter based on exclude criteria (any string in exclude must not be present)
if (!is.null(exclude)) {
exclude_indices <- sapply(exclude, function(exc) grepl(exc, extracted_names))
exclude_indices <- apply(exclude_indices, 1, any)
} else {
exclude_indices <- rep(FALSE, length(extracted_names))
}
final_indices <- include_indices & !exclude_indices
filtered_files <- all_files[final_indices]
# Return only the names of the filtered files
return(basename(filtered_files))
}
# ğŸŸ¥ ë°ì´í„° ë¡œë“œ =================================================================
path_data_1 = "/Users/Ido/Documents/GitHub/KFS_Timeseries_Data/5.á„ƒá…µá„Œá…µá„á…¥á†¯á„‰á…®á‡á„€á…¡á„á…®á„€á…µ/á„‰á…®á‡á„€á…¡á„á…®á„€á…µ(2020_2024)_1.xlsx"
path_data_2 = "/Users/Ido/Documents/GitHub/KFS_Timeseries_Data/5.á„ƒá…µá„Œá…µá„á…¥á†¯á„‰á…®á‡á„€á…¡á„á…®á„€á…µ/á„Œá…©á„…á…µá†·(2020_2024).xlsx"
# ìˆ²ê°€ê¾¸ê¸° 1 (2020 ~ 2022)
data_1 = read.xlsx(path_data_1)
View(data_1)
# ì¡°ë¦¼
data_2 = read.xlsx(path_data_2)
# names(data_1)
#
# View(data_1)
# ğŸŒ«ï¸ data1   ==============================================================================================
## ğŸŸª check  =======================================================================================
names(data_1)
## ğŸŸª year col  =======================================================================================
colnames(data_1)[1] = "year"
data_1$year %>% unique
## ğŸŸª subset 2020, 2021  =======================================================================================
data_1$year %>% class
data_1_sub = data_1 %>% filter(year  %in% c("2020", "2021"))
dim(data_1_sub)
## ğŸŸª check the data  =======================================================================================
View(data_1_sub)
## ğŸŸ© check the regions  =======================================================================================
data_1_sub$`GROUP_FIELD(í•„ì§€)` %>% unique
## ğŸŸ© Group regions  =======================================================================================
data_1_sub <- data_1_sub %>%
mutate(regions = case_when(
grepl("ê²½ê¸°ë„", `GROUP_FIELD(í•„ì§€)`) ~ "ê²½ê¸°ë„",
grepl("ê²½ìƒë‚¨ë„", `GROUP_FIELD(í•„ì§€)`) ~ "ê²½ìƒë‚¨ë„",
grepl("ì¶©ì²­ë‚¨ë„", `GROUP_FIELD(í•„ì§€)`) ~ "ì¶©ì²­ë‚¨ë„",
grepl("ì „ë¼ë‚¨ë„", `GROUP_FIELD(í•„ì§€)`) ~ "ì „ë¼ë‚¨ë„",
grepl("ì¶©ì²­ë¶ë„", `GROUP_FIELD(í•„ì§€)`) ~ "ì¶©ì²­ë¶ë„",
grepl("ê²½ìƒë¶ë„", `GROUP_FIELD(í•„ì§€)`) ~ "ê²½ìƒë¶ë„",
grepl("ëŒ€ì „ê´‘ì—­ì‹œ", `GROUP_FIELD(í•„ì§€)`) ~ "ëŒ€ì „ê´‘ì—­ì‹œ",
grepl("ì „ë¼ë¶ë„", `GROUP_FIELD(í•„ì§€)`) ~ "ì „ë¼ë¶ë„",
grepl("ê°•ì›ë„", `GROUP_FIELD(í•„ì§€)`) ~ "ê°•ì›ë„",
grepl("ê°•ì›íŠ¹ë³„ìì¹˜ë„", `GROUP_FIELD(í•„ì§€)`) ~ "ê°•ì›ë„",
grepl("ìš¸ì‚°ê´‘ì—­ì‹œ", `GROUP_FIELD(í•„ì§€)`) ~ "ìš¸ì‚°ê´‘ì—­ì‹œ",
grepl("ì„œìš¸íŠ¹ë³„ì‹œ", `GROUP_FIELD(í•„ì§€)`) ~ "ì„œìš¸íŠ¹ë³„ì‹œ",
grepl("ë¶€ì‚°ê´‘ì—­ì‹œ", `GROUP_FIELD(í•„ì§€)`) ~ "ë¶€ì‚°ê´‘ì—­ì‹œ",
grepl("ì¸ì²œê´‘ì—­ì‹œ", `GROUP_FIELD(í•„ì§€)`) ~ "ì¸ì²œê´‘ì—­ì‹œ",
grepl("ì œì£¼íŠ¹ë³„ìì¹˜ë„", `GROUP_FIELD(í•„ì§€)`) ~ "ì œì£¼íŠ¹ë³„ìì¹˜ë„",
grepl("ëŒ€êµ¬ê´‘ì—­ì‹œ", `GROUP_FIELD(í•„ì§€)`) ~ "ëŒ€êµ¬ê´‘ì—­ì‹œ",
grepl("ê´‘ì£¼ê´‘ì—­ì‹œ", `GROUP_FIELD(í•„ì§€)`) ~ "ê´‘ì£¼ê´‘ì—­ì‹œ",
grepl("ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ", `GROUP_FIELD(í•„ì§€)`) ~ "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ",
TRUE ~ "ê¸°íƒ€"
)) %>%
relocate(regions, .after = year)
# data_1_sub %>% filter(regi ons == "ì„œìš¸íŠ¹ë³„ì‹œ") %>% View
# ê²°ê³¼ í™•ì¸
head(data_1_sub)
data_1_sub$regions %>% table %>% as.data.frame()
# ê¸°íƒ€?
data_1_sub %>% filter(regions == "ê¸°íƒ€") %>% View
## ğŸŸ¨ í•„ìš”ì—´ë“¤ ì´ë¦„ ë³€ê²½  =======================================================================================
data_1_new = data_1_sub %>%
rename("work_area" = `PMS3A011_WORK_AREA(ì‚°ë¦¼ìì›ì¡°ì„±ì‚¬ì—…ì •ë³´.ì‘ì—…ë©´ì )`) %>%
rename("forest_tending" = `PMS3A011_FRCMB_NM1(ìˆ²ê°€ê¾¸ê¸°ë‚´ì—­.ì‘ì—…ì¢…1)`) %>%
relocate(work_area, forest_tending, .after = 2)
data_1_new$forest_tending %>% table
## ğŸŸ¨ ê° ì§€ì—­ë³„ ì—°ë„ë³„ ìˆ²ê°€ê¾¸ê¸° ë°ì´í„° í•©ì‚°  =======================================================================================
# ê° ì§€ì—­ë³„ë¡œ forest_tendingì— ë”°ë¼ work_areaë¥¼ í•©ì‚°í•œ ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ ìƒì„±
data_aggregated <- data_1_new %>%
group_by(regions, forest_tending, year) %>%
summarise(total_work_area = sum(work_area, na.rm = TRUE)) %>%
ungroup()
# ê²°ê³¼ í™•ì¸
data_aggregated %>% View
unique(data_1_new$regions) %in%  data_aggregated$regions
data_aggregated$regions %>% unique
# ê²€í† 
data_1_new %>%
filter(regions == "ê°•ì›ë„" &
forest_tending == "ì–´ë¦°ë‚˜ë¬´ê°€ê¾¸ê¸°" &
year == "2020") %>%
pull(work_area) %>%
sum(na.rm = T)
data_aggregated %>%
filter(regions == "ê°•ì›ë„" &
forest_tending == "ì–´ë¦°ë‚˜ë¬´ê°€ê¾¸ê¸°" &
year == "2020") %>%
pull(total_work_area)
## ğŸŸ¨ ì—°ë„ë³„ ì¬êµ¬ì„±  =======================================================================================
data_aggregated_2021 = data_aggregated %>% filter(year == "2021")
data_aggregated_2020 = data_aggregated %>% filter(year == "2020")
data_aggregated$year
## ğŸŸ¦ ì—°ë³´ë°ì´í„° ì¶”ì¶œ  =======================================================================================
### ğŸŸ§ ë°ì´í„° ë¡œë“œ ===================================================================================
# 2021ë…„ë„ ë°ì´í„° -> 2022 ì—°ë³´ë¥¼ ì˜ë¯¸
path_yb_2021 = "/Users/Ido/Documents/GitHub/KFS_Timeseries_Data/4.Exported Data_by ID_2/á„‰á…®á‡á„€á…¡á„á…®á„€á…µ/á„‰á…®á‡ á„€á…¡á„á…®á„€á…µForest tending/2022_YRBK_00520408.csv"
# 2020ë…„ë„ ë°ì´í„° -> 2021 ì—°ë³´ë¥¼ ì˜ë¯¸
path_yb_2020 = "/Users/Ido/Documents/GitHub/KFS_Timeseries_Data/4.Exported Data_by ID_2/á„‰á…®á‡á„€á…¡á„á…®á„€á…µ/á„‰á…®á‡ á„€á…¡á„á…®á„€á…µForest tending/2021_YRBK_00510409.csv"
yb_2021 = read.csv(path_yb_2021) %>% relocate(year, .after = 3)
yb_2020 = read.csv(path_yb_2020) %>% relocate(year, .after = 3)
View(yb_2021)
View(yb_2020)
### ğŸŸ§ Check names ===================================================================================
# names(yb_2021)
names(yb_2020)[3] = names(yb_2021)[3] = "classification"
names(yb_2020)[6] = names(yb_2021)[6] = "ì¡°ë¦¼ì§€ê°€ê¾¸ê¸°"
names(yb_2020)[9] = names(yb_2021)[9] = "ì–´ë¦°ë‚˜ë¬´ê°€ê¾¸ê¸°"
names(yb_2020)[10] = names(yb_2021)[10] = "í°ë‚˜ë¬´ê°€ê¾¸ê¸°"
### ğŸŸ§ Extract data ===================================================================================
View(yb_2021)
View(yb_2021)
yb_2021_sub = yb_2021 %>%
select(classification, ì¡°ë¦¼ì§€ê°€ê¾¸ê¸°, ì–´ë¦°ë‚˜ë¬´ê°€ê¾¸ê¸°, í°ë‚˜ë¬´ê°€ê¾¸ê¸°) %>%
filter(classification %in% data_aggregated$regions)
yb_2020_sub = yb_2020 %>%
select(classification, ì¡°ë¦¼ì§€ê°€ê¾¸ê¸°, ì–´ë¦°ë‚˜ë¬´ê°€ê¾¸ê¸°, í°ë‚˜ë¬´ê°€ê¾¸ê¸°) %>%
filter(classification %in% data_aggregated$regions)
### ğŸŸ§ ë°ì´í„°ì¬êµ¬ì„± ===================================================================================
yb_2021_sub %>% head
names(yb_2021_sub)
# ë°ì´í„° ë³€í™˜ í•¨ìˆ˜
transform_data <- function(data, year_value) {
data %>%
pivot_longer(cols = c("ì¡°ë¦¼ì§€ê°€ê¾¸ê¸°", "ì–´ë¦°ë‚˜ë¬´ê°€ê¾¸ê¸°", "í°ë‚˜ë¬´ê°€ê¾¸ê¸°"),
names_to = "forest_tending",
values_to = "total_work_area") %>%
rename(regions = classification) %>%
select(regions, forest_tending, total_work_area)
}
yb_2021_sub_2 = transform_data(yb_2021_sub)
yb_2020_sub_2 = transform_data(yb_2020_sub)
View(yb_2021_sub_2)
yb_2021_sub_2 %>% filter(regions == "ì„œìš¸íŠ¹ë³„ì‹œ")
# ğŸŸ¥ ë°ì´í„° í•©ì¹˜ê¸°  ===================================================================================
# ë°ì´í„° ì²´í¬
data_aggregated_2021
data_aggregated_2020
yb_2021_sub_2
yb_2020_sub_2
View(yb_2021)
names(data_aggregated_2021)
names(yb_2021_sub_2)
yb_2021_sub_2$forest_tending %>% table
data_aggregated_2021 %>% filter(regions == "ì„œìš¸íŠ¹ë³„ì‹œ")
yb_2021 %>% View
# ë‘ ë°ì´í„°í”„ë ˆì„ ë³‘í•© (regionsì™€ forest_tendingì„ ê¸°ì¤€ìœ¼ë¡œ)
combined_data_2021 <- left_join(data_aggregated_2021, yb_2021_sub_2,
by = c("regions", "forest_tending"),
suffix = c("_digital", "_yb"))
combined_data_2020 <- left_join(data_aggregated_2020, yb_2020_sub_2,
by = c("regions", "forest_tending"),
suffix = c("_digital", "_yb"))
# ğŸŸ¥ haë¡œ  unit ë°”ê¾¸ê¸°  ===================================================================================
combined_data_2021 = combined_data_2021 %>%
mutate(total_work_area_digital_ha = total_work_area_digital / 10000) %>%
mutate(diff_abs = abs(total_work_area_digital_ha - total_work_area_yb))
combined_data_2020 = combined_data_2020 %>%
mutate(total_work_area_digital_ha = total_work_area_digital / 10000) %>%
mutate(diff_abs = abs(total_work_area_digital_ha - total_work_area_yb))
View(combined_data_2020)
# ğŸŸ¥ export  ===================================================================================
path_save = "/Users/Ido/Documents/GitHub/KFS_Timeseries_Data/5.á„ƒá…µá„Œá…µá„á…¥á†¯á„‰á…®á‡á„€á…¡á„á…®á„€á…µ/Exported_2"
write.csv(combined_data_2020, file.path(path_save, "comparison 2020.csv"), row.names = F)
write.csv(combined_data_2021, file.path(path_save, "comparison 2021.csv"), row.names = F)
# ğŸŸ¥ Load Functions & Packages ##########################################################################
Sys.setlocale("LC_ALL", "en_US.UTF-8")
## ğŸŸ¨Install and loading Packages ================================
# rm(list = ls())
install_packages = function(packages, load=TRUE) {
# load : load the packages after installation?
for(pkg in packages) {
if (!require(pkg, character.only = TRUE)) {
install.packages(pkg)
}
if(load){
library(pkg, character.only = TRUE, quietly = T)
}
}
}
List.list = list()
List.list[[1]] = visual = c("ggpubr", "ggplot2", "ggstatsplot", "ggsignif", "rlang", "RColorBrewer")
List.list[[2]] = stat = c("fda", "MASS")
List.list[[3]] = data_handling = c("tidyverse", "dplyr", "clipr", "tidyr", "readr", "caret", "readxl")
List.list[[4]] = qmd = c("janitor", "knitr")
List.list[[5]] = texts = c("stringr", "stringi")
List.list[[6]] = misc = c("devtools")
List.list[[7]] = db = c("RMySQL", "DBI", "odbc", "RSQL", "RSQLite")
List.list[[8]] = sampling = c("rsample")
List.list[[9]] = excel = c("openxlsx")
List.list[[10]] = others = c("beepr")
packages_to_install_and_load = unlist(List.list)
install_packages(packages_to_install_and_load)
## ğŸŸ§dplyr ==================================================================================================
filter = dplyr::filter
select = dplyr::select
# ğŸŸ¥ =========================================================================================================
list.files("/Volumes/ADNI_SB_SSD_NTFS_4TB_Sandisk/New/Completed_GE.MEDICAL.SYSTEMS/GE.MEDICAL.SYSTEMS_SB___Sub_001___RID_0074___EPB_I1120325___MT1_I1120324/Results")
