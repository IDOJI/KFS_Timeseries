# ğŸŸ¥ Load Functions & Packages ##########################################################################
# rm(list = ls())
## ğŸŸ¨Install and loading Packages ================================
install_packages = function(packages, load=TRUE) {
  # load : load the packages after installation?
  for(pkg in packages) {
    if (!require(pkg, character.only = TRUE)) {
      install.packages(pkg)
    }
    
    if(load){
      library(pkg, character.only = TRUE, quietly = T)
    }
  }
}

List.list = list()
List.list[[1]] = visual = c("ggpubr", "ggplot2", "ggstatsplot", "ggsignif", "rlang", "RColorBrewer")
List.list[[2]] = stat = c("fda", "MASS")
List.list[[3]] = data_handling = c("tidyverse", "dplyr", "clipr", "tidyr", "readr", "caret", "readxl")
List.list[[4]] = qmd = c("janitor", "knitr")
List.list[[5]] = texts = c("stringr")
List.list[[6]] = misc = c("devtools")
List.list[[7]] = db = c("RMySQL", "DBI", "odbc", "RSQL", "RSQLite")
List.list[[8]] = sampling = c("rsample")
List.list[[9]] = excel = c("openxlsx")

packages_to_install_and_load = unlist(List.list)
install_packages(packages_to_install_and_load)



## ğŸŸ§dplyr =======================================================
filter = dplyr::filter
select = dplyr::select





## ğŸŸ§Loading my functions ======================================================
load_functions = function(path_functions){
  list.files(path_functions, full.names = T) %>%
    purrr::walk(source)
}
path_list = list()
path_list[1] = "/Users/Ido/Library/CloudStorage/Dropbox/1.GitHub/R___refineR/R"
path_list[2] = "/Users/Ido/Library/CloudStorage/Dropbox/1.GitHub/R___StatsR/R"
Load = sapply(path_list, load_functions)






# ğŸŸ¥ Define a clustering function #####################################################################################################
## ğŸŸ§ í•„ìš”í•œ íŒ¨í‚¤ì§€ ë¡œë“œ ##############################################################################################################
library(tm)
library(proxy)
library(cluster)
library(factoextra)
library(showtext)
font_add_google(name = "Nanum Gothic", family = "nanumgothic")
showtext_auto()
library(tm)
library(cluster)
library(factoextra)





## ğŸŸ§ í…ìŠ¤íŠ¸ í´ëŸ¬ìŠ¤í„°ë§ í•¨ìˆ˜ ì •ì˜ ##############################################################################################################
text_clustering <- function(text_data, special_cases = list(), k_min = 2, k_max = length(text_data)-1) {
  # ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì €ì¥í•  ë²¡í„° ìƒì„±
  cleaned_vector <- text_data
  
  # íŠ¹ë³„ ì¼€ì´ìŠ¤ë¥¼ ì ìš©
  for (case in names(special_cases)) {
    cleaned_vector <- gsub(case, special_cases[[case]], cleaned_vector)
  }
  
  # ìˆ«ì, ë°‘ì¤„, ë§ˆì¹¨í‘œ ì œê±°
  cleaned_vector <- gsub("[0-9_.]", "", cleaned_vector)
  
  # í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì½”í¼ìŠ¤ë¡œ ë³€í™˜ (cleaned_vector ì‚¬ìš©)
  corpus <- Corpus(VectorSource(cleaned_vector))
  
  # ìš©ì–´ ë¬¸ì„œ í–‰ë ¬ ìƒì„±
  tdm <- TermDocumentMatrix(corpus, control = list(wordLengths = c(1, Inf)))
  tdm_matrix <- as.matrix(tdm)
  tdm_matrix <- t(tdm_matrix)
  
  # TF-IDF ê°€ì¤‘ì¹˜ ë¶€ì—¬
  tfidf_transform <- weightTfIdf(tdm)
  tdm_matrix <- as.matrix(tfidf_transform)
  tdm_matrix <- t(tdm_matrix)
  
  # ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì—´ ì œê±°
  non_zero_columns <- apply(tdm_matrix, 2, function(col) sum(col != 0)) > 1
  tdm_matrix <- tdm_matrix[, non_zero_columns]
  
  # ë°ì´í„° í¬ì¸íŠ¸ì˜ ìˆ˜ê°€ í´ëŸ¬ìŠ¤í„° ìˆ˜ë³´ë‹¤ ë§ì€ì§€ í™•ì¸
  num_data_points <- nrow(tdm_matrix)
  if (k_max > num_data_points) {
    stop("k_max is greater than the number of distinct data points.")
  }
  
  # ì‹¤ë£¨ì—£ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ìˆ˜ ì„ íƒ
  silhouette_score <- function(k) {
    km <- kmeans(tdm_matrix, centers = k, nstart = 25)
    ss <- silhouette(km$cluster, dist(tdm_matrix))
    mean(ss[, 3])
  }
  
  k_values <- k_min:k_max
  avg_sil <- sapply(k_values, silhouette_score)
  
  best_k <- k_values[which.max(avg_sil)]
  print(paste("Best number of clusters:", best_k))
  
  # K-means í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
  km <- kmeans(tdm_matrix, centers = best_k, nstart = 25)
  
  # ì›ë˜ì˜ text_dataì™€ í´ëŸ¬ìŠ¤í„° í• ë‹¹ì„ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ì €ì¥
  data_clusters <- data.frame(text = text_data, cluster = km$cluster)
  data_clusters <- data_clusters[order(data_clusters$cluster), ]
  
  # í´ëŸ¬ìŠ¤í„°ë³„ í…ìŠ¤íŠ¸ ëª©ë¡ ìƒì„± (ì›ë˜ì˜ text_data ì‚¬ìš©)
  clusters_list <- lapply(unique(data_clusters$cluster), function(cluster) {
    data_clusters$text[data_clusters$cluster == cluster]
  })
  
  # í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ì‹œê°í™”
  plot_cluster <- fviz_cluster(km, data = tdm_matrix, geom = "point", labelsize = 5, ggtheme = theme_minimal())
  
  tdm_matrix_pca <- prcomp(tdm_matrix, scale. = TRUE)
  tdm_matrix_pca_data <- as.data.frame(tdm_matrix_pca$x)
  tdm_matrix_pca_data$cluster <- as.factor(km$cluster)
  
  plot_pca <- fviz_pca_ind(tdm_matrix_pca, geom = "point", habillage = tdm_matrix_pca_data$cluster, 
                           addEllipses = TRUE, ellipse.level = 0.95, ggtheme = theme_minimal())
  
  # ê²°ê³¼ ë°˜í™˜
  return(list(clusters = clusters_list, plot_cluster = plot_cluster, plot_pca = plot_pca, tdm_matrix = tdm_matrix, data_clusters = data_clusters))
}






## ğŸŸ§ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ í•©ì¹˜ëŠ” í•¨ìˆ˜ ì •ì˜ ##############################################################################################################
merge_clusters <- function(clustering_result, combined.list) {
  # ê¸°ì¡´ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
  data_clusters <- clustering_result$data_clusters
  tdm_matrix <- clustering_result$tdm_matrix
  
  # ìƒˆë¡œìš´ í´ëŸ¬ìŠ¤í„°ë§ ê·¸ë£¹ í• ë‹¹
  data_clusters$new_cluster <- NA
  for (i in 1:length(combined.list)) {
    data_clusters$new_cluster[data_clusters$cluster %in% combined.list[[i]]] <- i
  }
  
  # ìƒˆë¡œìš´ í´ëŸ¬ìŠ¤í„° ë¦¬ìŠ¤íŠ¸ ìƒì„±
  new_clusters_list <- lapply(seq_along(combined.list), function(kth_cluster) {
    data_clusters %>% filter(new_cluster == kth_cluster) %>% pull(text)
  }) %>% setNames(names(combined.list))
  
  
  # PCA ì‹œê°í™” ì¤€ë¹„
  tdm_matrix_pca <- prcomp(tdm_matrix, scale. = TRUE)
  tdm_matrix_pca_data <- as.data.frame(tdm_matrix_pca$x)
  tdm_matrix_pca_data$cluster <- as.factor(data_clusters$new_cluster)
  
  plot_pca <- ggplot(tdm_matrix_pca_data, aes(x = PC1, y = PC2, color = cluster)) +
    geom_point(size = 2) +
    stat_ellipse(level = 0.95) +
    theme_minimal() +
    labs(title = "PCA of Merged Clusters")
  
  # í´ëŸ¬ìŠ¤í„° ì‹œê°í™” ì¤€ë¹„
  plot_cluster <- ggplot(tdm_matrix_pca_data, aes(x = PC1, y = PC2, color = cluster)) +
    geom_point(size = 2) +
    theme_minimal() +
    labs(title = "Merged Clusters Visualization")
  
  return(list(clusters = new_clusters_list, plot_cluster = plot_cluster, plot_pca = plot_pca, data_clusters = data_clusters))
}








## ğŸŸ§ ì‚¬ìš© ì˜ˆì‹œ ##############################################################################################################
# ì˜ˆì‹œ ë°ì´í„°
# text_data <- c("ì˜ˆì‹œ ë¬¸ì¥1", "ì˜ˆì‹œ ë¬¸ì¥2", "ì˜ˆì‹œ ë¬¸ì¥3", "ì˜ˆì‹œ ë¬¸ì¥4", "ì˜ˆì‹œ ë¬¸ì¥5", 
#                "ì˜ˆì‹œ ë¬¸ì¥6", "ì˜ˆì‹œ ë¬¸ì¥7", "ì˜ˆì‹œ ë¬¸ì¥8", "ì˜ˆì‹œ ë¬¸ì¥9", "ì˜ˆì‹œ ë¬¸ì¥10",
#                "ì˜ˆì‹œ ë¬¸ì¥11", "ì˜ˆì‹œ ë¬¸ì¥12", "ì˜ˆì‹œ ë¬¸ì¥13", "ì˜ˆì‹œ ë¬¸ì¥14", "ì˜ˆì‹œ ë¬¸ì¥15",
#                "ì˜ˆì‹œ ë¬¸ì¥16", "ì˜ˆì‹œ ë¬¸ì¥17", "ì˜ˆì‹œ ë¬¸ì¥18", "ì˜ˆì‹œ ë¬¸ì¥19", "ì˜ˆì‹œ ë¬¸ì¥20")
# 
# result_1 <- text_clustering(text_data, k_min = 8, k_max = 8)
# result_1$clusters
# result_1$data_clusters
# # ê²°ê³¼ ì¶œë ¥ ë° ì‚¬ìš©ì ì •ì˜ í´ëŸ¬ìŠ¤í„° í•©ì¹˜ê¸°
# combined.list <- list(c(1, 2, 3, 4, 7), c(5, 6), 8)
# merged_result <- merge_clusters(result_1, combined.list)
# 
# # ë³‘í•©ëœ í´ëŸ¬ìŠ¤í„° ê²°ê³¼ ì¶œë ¥
# print(merged_result$clusters)

# ì‹œê°í™” ì¶œë ¥
# print(merged_result$plot_cluster)
# print(merged_result$plot_pca)





## ğŸŸ§ ì—¬ëŸ¬ ê°œì˜ ì›ì†Œì— unionì„ ì ìš©í•˜ëŠ” í•¨ìˆ˜ ì •ì˜ ##############################################################################################################
# union_multiple í•¨ìˆ˜ ì •ì˜
union_multiple <- function(...) {
  lists <- list(...)
  result <- Reduce(union, lists)
  return(result)
}



## ğŸŸ§ í…ìŠ¤íŠ¸ í•„í„°ë§ í•¨ìˆ˜ ##############################################################################################################
# ëŒ€ì†Œë¬¸ì êµ¬ë³„ ì—†ì´ í•„í„°ë§í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
# ëŒ€ì†Œë¬¸ì êµ¬ë³„ ì—†ì´ í•„í„°ë§í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
filter_text_data <- function(text_data, include = NULL, exclude = NULL) {
  if (!is.null(include)) {
    for (inc in include) {
      text_data <- text_data[grep(inc, text_data, ignore.case = TRUE)]
    }
  }
  
  if (!is.null(exclude)) {
    for (exc in exclude) {
      text_data <- text_data[!grepl(exc, text_data, ignore.case = TRUE)]
    }
  }
  
  return(text_data)
}


## ğŸŸ§ ì¤‘ë³µí•­ëª©í™•ì¸ í•¨ìˆ˜ ##############################################################################################################
find_duplicates <- function(list) {
  any_duplicates_found <- FALSE
  for (category in names(list)) {
    duplicated_items <- duplicated(list[[category]]) | duplicated(list[[category]], fromLast = TRUE)
    if (any(duplicated_items)) {
      any_duplicates_found <- TRUE
      cat("Category:", category, "\n")
      cat("Duplicates:", list[[category]][duplicated_items], "\n\n")
    }
  }
  
  if (!any_duplicates_found) {
    cat("ì „ì²´ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¤‘ë³µ í•­ëª© ì—†ìŒ\n")
  }
}

## ğŸŸ§ L3 ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜ ==================================================================
extract_L3_values <- function(data, include_keywords, exclude_keywords = NULL) {
  # L2 ì—´ì—ì„œ í¬í•¨í•  í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ê³ ìœ í•œ ì›ì†Œ ì¶”ì¶œ
  matched_L2_values <- unique(data$L2[grep(paste(include_keywords, collapse = "|"), data$L2)])
  
  # ì œì™¸í•  í‚¤ì›Œë“œê°€ ì£¼ì–´ì§€ë©´ í•´ë‹¹ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ì›ì†Œ ì œê±°
  if (!is.null(exclude_keywords)) {
    exclude_pattern <- paste(exclude_keywords, collapse = "|")
    matched_L2_values <- matched_L2_values[!grepl(exclude_pattern, matched_L2_values)]
  }
  
  # ì¶”ì¶œëœ L2 ê°’ì„ ê°–ëŠ” í–‰ë“¤ì˜ L3 ê°’ ì¶”ì¶œ
  matched_L3_values <- unique(data$L3[data$L2 %in% matched_L2_values])
  
  return(matched_L3_values)
}


# ğŸŸ¥ Data Load #####################################################################################################
# íŒŒì¼ ê²½ë¡œë¥¼ ë³€ìˆ˜ì— ì €ì¥
file_path = "/Users/Ido/Library/CloudStorage/GoogleDrive-clair.de.lune.404@gmail.com/My Drive/DataAnalysis/KFS_Timeseries/rearranged data/1.Sorted_YB_Names.csv"
data = read.csv(file_path)
L2 = data$L2 %>% table %>% names
length(L2)




# ğŸŸ¥ clustering L2 category #####################################################################################################
k=22
clutered_L2 = text_clustering(L2, k_min = k, k_max = k)
clutered_L2$plot_cluster
clutered_L2$clusters




# ğŸŸ¥ L2 ì¹´í…Œê³ ë¦¬ ë¬¶ê¸° #####################################################################################################
## ğŸŸ§ ë°ì´í„° ======================================================================================
text_data = L2

## ğŸŸ§ ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸ ======================================================================================
combined.list = list()


## ğŸŸ© êµ­ë¯¼ ê³„ì •ê³¼ ìƒì‚°ê°€ê²©ì§€ìˆ˜ ======================================================================================
combined.list$`êµ­ë¯¼ê³„ì •ê³¼ ìƒì‚°ê°€ê²©ì§€ìˆ˜_National Accounts and Index number of Products Price` =
  union_multiple(filter_text_data(text_data, c("national", "accounts", "index", "number", "products", "price")),
                 filter_text_data(text_data, c("êµ­ë¯¼ê³„ì •", "ìƒì‚°ê°€ê²©ì§€ìˆ˜")))
## ğŸŸ© ì¡°ë¦¼/ë³´í˜¸/ì‚°ë¦¼ì˜ ê±´ê°• ë° ë‹¤ì–‘ì„± ======================================================================================
combined.list$`ì¡°ë¦¼/ë³´í˜¸/ì‚°ë¦¼ì˜ ê±´ê°• ë° ë‹¤ì–‘ì„±_Reforestation/protection/Forest Health and Diversity` =
  union_multiple(filter_text_data(text_data, c("forest", "health", "diversity")),
                 filter_text_data(text_data, c("ì‚°ë¦¼", "ê±´ê°•", "ë‹¤ì–‘ì„±")),
                 filter_text_data(text_data, c("forest", "protection"), "reforestation"),
                 filter_text_data(text_data, c("ì‚°ë¦¼", "ë³´í˜¸"), "ì¡°ë¦¼"),
                 filter_text_data(text_data, c("reforestation", "protection")),
                 filter_text_data(text_data, c("ì¡°ë¦¼", "ë³´í˜¸")),
                 filter_text_data(text_data, c("ì¡°ë¦¼", "ì‚¬ë°©")))
# clustering_ì¡°ë¦¼ = text_clustering(extract_L3_values(data, c("ì¡°ë¦¼", "ì‚¬ë°©")),
#                                 k_min=30, k_max=30)
## ğŸŸ© êµ­í† ì™€ ìì—°í™˜ê²½ ======================================================================================
combined.list$`êµ­í† ì™€ ìì—°í™˜ê²½_Land & Natural Environment` =
  union_multiple(filter_text_data(text_data, c("land", "natural", "environment")),
                 filter_text_data(text_data, c("êµ­í† ", "ìì—°", "í™˜ê²½")))
# clustering_êµ­í†  = text_clustering(extract_L3_values(data, c("êµ­í† ", "í™˜ê²½")),
#                                 k_min=30, k_max=30)
# clustering_êµ­í† $clusters
## ğŸŸ© êµ­ì œí†µê³„ ======================================================================================
combined.list$`êµ­ì œ ì‚°ë¦¼ í†µê³„_International Statistics` =
  union_multiple(filter_text_data(text_data, c("international", "statistics")),
                 filter_text_data(text_data, c("êµ­ì œ", "í†µê³„")),
                 filter_text_data(text_data, c("êµ­ì œ", "ì‚°ë¦¼")))
## ğŸŸ© ì„ì•¼ë©´ì  ë° ì„ëª©ì¶•ì  ======================================================================================
combined.list$`ì„ì•¼/ì‚°ë¦¼ë©´ì  ë° ì„ëª©ì¶•ì _Forest Land Area & Growing Stock` =
  union_multiple(filter_text_data(text_data, 
                                  c("forest", "land", "area", "growing", "stock"),
                                  "êµ­ìœ ë¦¼"),
                 filter_text_data(text_data, 
                                  c("ë©´ì ", "ì„ëª©", "ì¶•ì "), 
                                  "êµ­ìœ ë¦¼"),
                 filter_text_data(text_data, 
                                  c("ì—°ë„ë³„", "ì„ìƒ", "ë©´ì "), 
                                  "êµ­ìœ ë¦¼"))
## ğŸŸ© ì„ì‚°ë¬¼ ê°€ê²© ë° ê¸°íƒ€ ê°€ê²© ======================================================================================
combined.list$`ì„ì‚°ë¬¼ ê°€ê²© ë° ê¸°íƒ€ê°€ê²©_Price of forest Products & Major Commodities` =
  union_multiple(filter_text_data(text_data, c("price", "forest", "product", "major", "commodities")),
                 filter_text_data(text_data, c("ì„ì‚°ë¬¼", "ê¸°íƒ€","ê°€ê²©")))
## ğŸŸ© ì„ì‚°ë¬¼ ì‹œì¥ ======================================================================================
combined.list$`ì„ì‚°ë¬¼ì‹œì¥_Forest Product Market` =
  union_multiple(filter_text_data(text_data, c("market", "forest", "product")),
                 filter_text_data(text_data, c("ì„ì‚°ë¬¼", "ì‹œì¥")),
                 filter_text_data(text_data, c("ì„ì‚°ë¬¼", "ë¬´ì—­", "ê°€ê³µ")))
# clustering_1 = text_clustering(extract_L3_values(data, c("ì„ì‚°ë¬¼", "ì‹œì¥")),
#                              k_min=30, k_max=30)
# clustering_1$clusters
# filter_text_data(text_data, c("marketing", "forest", "product"))
# clustering_2 = text_clustering(extract_L3_values(data, c("ì„ì‚°ë¬¼", "ë¬´ì—­", "ê°€ê³µ", "ìœ í†µ")),
#                              k_min=30, k_max=30)
# clustering_2$clusters
## ğŸŸ© ë¶€ë¡ ======================================================================================
combined.list$`ë¶€ë¡_Appendix` =
  union_multiple(filter_text_data(text_data, c("appendix")),
                 filter_text_data(text_data, c("ë¶€ë¡")))
## ğŸŸ© ì„ì•¼/ì‚°ë¦¼ ìì› (forest resources) ======================================================================================
combined.list$`ì„ì•¼/ì‚°ë¦¼ ìì› ì¡°ì„±_Silviculture` =
  union_multiple(filter_text_data(text_data, c("silviculture")),
                 filter_text_data(text_data, 
                                  c("ì„ì•¼", "ìì›", "ì¡°ì„±")),
                 filter_text_data(text_data, 
                                  c("ì‚°ë¦¼", "ìì›", "ì¡°ì„±")),
                 filter_text_data(text_data, 
                                  c("forest", "resources"), 
                                  c("Silviculture", "ì¡°ì„±")))
# clustering_1 = text_clustering(extract_L3_values(data, c("ì‚°ë¦¼", "ìì›", "ì¡°ì„±", "ì´ìš©")),
#                                k_min=20, k_max=20)
# clustering_1$clusters
# clustering_2 = text_clustering(extract_L3_values(data, c("Silviculture")),
#                                k_min=20, k_max=20)
# clustering_2$clusters
# filter_text_data(text_data, c("forest", "resource"))
# clustering_2 = text_clustering(extract_L3_values(data, c("forest", "resource")),
#                              k_min=30, k_max=30)
# clustering_2$clusters
## ğŸŸ© ìš©ë„ë³„ ì‚°ì§€ ì´ìš© êµ¬ë¶„ ======================================================================================
combined.list$` ìš©ë„ë³„ ì‚°ì§€ ì´ìš©êµ¬ë¶„ ì¡°ì‚¬ì‹¤ì _Forest Land Use Classification` =
  union_multiple(filter_text_data(text_data, 
                                  c("ìš©ë„ë³„", "ì‚°ì§€")))
## ğŸŸ© ì„ì•¼/ì‚°ë¦¼ ê²½ì˜ ======================================================================================
combined.list$`ì„ì—…/ì‚°ë¦¼ ê²½ì˜_Forest Management` =
  union_multiple(filter_text_data(text_data, 
                                  c("forest", "management")),
                 filter_text_data(text_data, 
                                  c("ì‚°ë¦¼", "ê²½ì˜")),
                 filter_text_data(text_data, 
                                  c("ì„ì—…", "ê²½ì˜")),
                 filter_text_data(text_data, 
                                  c("êµ­ìœ ë¦¼", "ê´€ë¦¬")))
# clustering_ìš©ë„ë³„ = text_clustering(extract_L3_values(data, c("ì‚°ì§€",  "ìš©ë„ë³„")),
#                              k_min=1, k_max=1)
# clustering_ìš©ë„ë³„$clusters
# clustering = text_clustering(extract_L3_values(data, c("forest",  "management"), "national"),
#                              k_min=30, k_max=30)
# clustering$clusters
# clustering_4 = text_clustering(extract_L3_values(data, c("national", "forest",  "management", "ê²½ì˜")),
#                              k_min=30, k_max=30)
# clustering_4$clusters
## ğŸŸ© ì„ì•¼/ì‚°ë¦¼ ì„œë¹„ìŠ¤ ======================================================================================
combined.list$`ì„ì•¼/ì‚°ë¦¼ ì„œë¹„ìŠ¤_Forest Service` =
  union_multiple(filter_text_data(text_data, c("forest", "service")),
                 filter_text_data(text_data, c("ì‚°ë¦¼", "ì„œë¹„ìŠ¤")),
                 filter_text_data(text_data, c("ì„ì•¼", "ì„œë¹„ìŠ¤")))
# clustering_5 = text_clustering(extract_L3_values(data, c("forest", "service")),
#                              k_min=30, k_max=30)
# clustering_5$clusters
## ğŸŸ© ì„ì—… ìƒì‚° ======================================================================================
combined.list$`ì„ì—…ìƒì‚°_Forest production` =
  union_multiple(filter_text_data(text_data, c("forest", "production")),
                 filter_text_data(text_data, c("ì„ì—…", "ìƒì‚°")))
# clustering_6 = text_clustering(extract_L3_values(data, c("êµ­ë¯¼", "forest", "ì´ìƒì‚°")),
#                              k_min=30, k_max=30)
# clustering_6$clusters
# clustering_7 = text_clustering(extract_L3_values(data, c("forest", "ì´ìƒì‚°"), "êµ­ë¯¼"),
#                                k_min=30, k_max=30)
# clustering_7$clusters
## ğŸŸ© êµìœ¡ í›ˆë ¨ ======================================================================================
combined.list$`êµìœ¡ í›ˆë ¨_Education and Training` =
  union_multiple(filter_text_data(text_data, c("education", "training")),
                 filter_text_data(text_data, c("êµìœ¡", "í›ˆë ¨")))
## ğŸŸ© ì„ì‚° ë¬´ì—­ ê°€ê³µ ë° ìœ í†µ ======================================================================================
combined.list$`ì„ì‚° ë¬´ì—­ ê°€ê³µ ë° ìœ í†µ_Trede Processing and marketing of forest products` =
  union_multiple(filter_text_data(text_data, c("trade", "processing", "marketing", "forest", "products")),
                 filter_text_data(text_data, c("ì„ì‚°", "ë¬´ì—­", "ê°€ê³µ", "ìœ í†µ")),
                 filter_text_data(text_data, c("ì„ì‚°", "ë¬´ì—­", "ê°€ê³µ")))
# clustering_8 = text_clustering(extract_L3_values(data, c("trade", "processing")),
#                                k_min=30, k_max=30)
# clustering_8$clusters
## ğŸŸ© ì‚¬ìœ ë¦¼ ê´€ë¦¬ ======================================================================================
combined.list$`ì‚¬ìœ ë¦¼ ê´€ë¦¬_Private Forest Administration` =
  union_multiple(filter_text_data(text_data, c("private", "forest")),
                 filter_text_data(text_data, c("ì‚¬ìœ ë¦¼", "ê´€ë¦¬")),
                 filter_text_data(text_data, c("ì‚¬ìœ ë¦¼")))
# clustering_ì‚¬ìœ ë¦¼ = text_clustering(extract_L3_values(data, c("ì‚¬ìœ ë¦¼", "ê´€ë¦¬")),
#                                k_min=30, k_max=30)
# clustering_ì‚¬ìœ ë¦¼$clusters
## ğŸŸ© ì¬ì •ê³¼ ê¸ˆìœµ ======================================================================================
combined.list$`ì¬ì •ê³¼ ê¸ˆìœµ_Finances and Loans` =
  union_multiple(filter_text_data(text_data, c("finance", "loan")),
                 filter_text_data(text_data, c("ì¬ì •", "ê¸ˆìœµ")))



## ğŸŸ§ í•„í„°ë§ ê²°ê³¼ í™•ì¸ ======================================================================================
filtered_data <- unlist(combined.list)
unfiltered_data <- setdiff(text_data, filtered_data)

k=5
# ì—ëŸ¬ ë°œìƒ ì‹œ print(unfiltered_data)ë¥¼ ì‹¤í–‰
tryCatch({
  # í´ëŸ¬ìŠ¤í„°ë§ í•¨ìˆ˜ ì‹¤í–‰
  clustering_result <- text_clustering(unfiltered_data, k_min = k, k_max = k)
  print(clustering_result$cluster)  # í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ì¶œë ¥
}, error = function(e) {
  # ì—ëŸ¬ê°€ ë°œìƒí•˜ë©´ unfiltered_dataë¥¼ ì¶œë ¥
  print(unfiltered_data)
})

if (length(unfiltered_data) > 0) {
  cat("í•„í„°ë§ë˜ì§€ ì•Šì€ ì›ì†Œê°€ ì¡´ì¬í•©ë‹ˆë‹¤:\n")
  print(unfiltered_data)
} else {
  cat("ëª¨ë“  ì›ì†Œê°€ í•„í„°ë§ë˜ì—ˆìŠµë‹ˆë‹¤.\n")
}


# ğŸŸ¥ ì¤‘ë³µì›ì†Œ í™•ì¸ ==============================================================================
find_duplicates(combined.list)
names(combined.list)


# ğŸŸ¥ í•˜ë‚˜ì˜ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ í•©ì¹˜ê¸° ==============================================================================
# ìƒˆë¡œìš´ ì—´ ìƒì„±
combined_data = data
combined_data$Categorized_L2 <- NA

# ê° ì¹´í…Œê³ ë¦¬ ì´ë¦„ì„ í•´ë‹¹ L2 ê°’ì— í• ë‹¹
for (category_name in names(combined.list)) {
  category_values <- combined.list[[category_name]]
  combined_data$Categorized_L2[combined_data$L2 %in% category_values] <- category_name
}
combined_data = combined_data %>% relocate(Categorized_L2)



# ğŸŸ¥ Export ==============================================================================
path_save = "/Users/Ido/Library/CloudStorage/GoogleDrive-clair.de.lune.404@gmail.com/My Drive/DataAnalysis/KFS_Timeseries/rearranged data"
write.csv(combined_data, paste0(path_save, "/2.L2 Categorized data.csv"), row.names=F)










